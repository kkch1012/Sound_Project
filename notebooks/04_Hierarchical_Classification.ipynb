{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš— ê³„ì¸µì  ë¶„ë¥˜ ëª¨ë¸ (Hierarchical Classification)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ê³„ì¸µì  ë¶„ë¥˜ ì ‘ê·¼ë²•ìœ¼ë¡œ ì°¨ëŸ‰ ì‚¬ìš´ë“œë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ğŸ“‹ ëª©ì°¨\n",
        "1. **1ë‹¨ê³„ ëª¨ë¸**: ìƒíƒœ(State) ë¶„ë¥˜ - ë¸Œë ˆì´í¬/ê³µíšŒì „/ì‹œë™\n",
        "2. **êµ°ì§‘ ë¶„ì„**: PCA ì‹œê°í™” + K-means í´ëŸ¬ìŠ¤í„°ë§\n",
        "3. **2ë‹¨ê³„ ëª¨ë¸**: ê° ìƒíƒœë³„ ì„¸ë¶€ ë¬¸ì œ ë¶„ë¥˜\n",
        "   - ë¸Œë ˆì´í¬ ìƒíƒœ ì„¸ë¶€ ë¶„ë¥˜\n",
        "   - ê³µíšŒì „ ìƒíƒœ ì„¸ë¶€ ë¶„ë¥˜\n",
        "   - ì‹œë™ ìƒíƒœ ì„¸ë¶€ ë¶„ë¥˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ë¨¸ì‹ ëŸ¬ë‹\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, \n",
        "    adjusted_rand_score, normalized_mutual_info_score,\n",
        "    silhouette_score\n",
        ")\n",
        "import seaborn as sns\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import librosa\n",
        "\n",
        "# í”„ë¡œì íŠ¸ ëª¨ë“ˆ\n",
        "from app.ml.models.crnn import SoundClassifierCRNN\n",
        "from app.ml.features.extractor import AudioFeatureExtractor, AudioConfig\n",
        "from app.ml.features.augmentation import AudioAugmentor, AugmentationConfig\n",
        "from app.ml.training.trainer import Trainer, create_optimizer, create_scheduler\n",
        "\n",
        "# ì‹œê°í™” ì„¤ì •\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\")\n",
        "print(f\"ğŸ–¥ï¸ Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ë°ì´í„° ê²½ë¡œ ìˆ˜ì§‘\n",
        "# ============================================================\n",
        "\n",
        "data_dir = Path('../data')\n",
        "augmented_dir = data_dir / 'augmented'\n",
        "\n",
        "# íŒŒì¼ ê²½ë¡œì™€ ë ˆì´ë¸” ìˆ˜ì§‘\n",
        "all_files = []\n",
        "all_states = []      # 1ë‹¨ê³„: ìƒíƒœ (braking, idle, startup)\n",
        "all_problems = []    # 2ë‹¨ê³„: ì„¸ë¶€ ë¬¸ì œ\n",
        "\n",
        "# ìƒíƒœ ë§¤í•‘\n",
        "state_mapping = {\n",
        "    'braking state': 0,\n",
        "    'idle state': 1,\n",
        "    'startup state': 2\n",
        "}\n",
        "state_names = ['braking', 'idle', 'startup']\n",
        "\n",
        "print(\"ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
        "\n",
        "# ì›ë³¸ ë°ì´í„° ìˆ˜ì§‘\n",
        "for state_dir in sorted(data_dir.iterdir()):\n",
        "    if not state_dir.is_dir() or state_dir.name == 'augmented':\n",
        "        continue\n",
        "    \n",
        "    state_name = state_dir.name\n",
        "    state_idx = state_mapping.get(state_name, -1)\n",
        "    \n",
        "    if state_idx == -1:\n",
        "        continue\n",
        "    \n",
        "    for problem_dir in sorted(state_dir.iterdir()):\n",
        "        if not problem_dir.is_dir():\n",
        "            continue\n",
        "        \n",
        "        problem_name = problem_dir.name\n",
        "        \n",
        "        # WAV íŒŒì¼ ìˆ˜ì§‘\n",
        "        wav_files = list(problem_dir.glob('*.wav'))\n",
        "        for f in wav_files:\n",
        "            all_files.append(f)\n",
        "            all_states.append(state_idx)\n",
        "            all_problems.append(f\"{state_name}/{problem_name}\")\n",
        "        \n",
        "        # í•˜ìœ„ í´ë”ë„ í™•ì¸ (combined ë“±)\n",
        "        for sub_dir in problem_dir.iterdir():\n",
        "            if sub_dir.is_dir():\n",
        "                sub_files = list(sub_dir.glob('*.wav'))\n",
        "                for f in sub_files:\n",
        "                    all_files.append(f)\n",
        "                    all_states.append(state_idx)\n",
        "                    all_problems.append(f\"{state_name}/{problem_name}/{sub_dir.name}\")\n",
        "\n",
        "original_count = len(all_files)\n",
        "print(f\"   ì›ë³¸ ìƒ˜í”Œ: {original_count}ê°œ\")\n",
        "\n",
        "# ì¦ê°• ë°ì´í„° ìˆ˜ì§‘\n",
        "if augmented_dir.exists():\n",
        "    for state_dir in sorted(augmented_dir.iterdir()):\n",
        "        if not state_dir.is_dir():\n",
        "            continue\n",
        "        \n",
        "        state_name = state_dir.name\n",
        "        state_idx = state_mapping.get(state_name, -1)\n",
        "        \n",
        "        if state_idx == -1:\n",
        "            continue\n",
        "        \n",
        "        for problem_dir in sorted(state_dir.iterdir()):\n",
        "            if not problem_dir.is_dir():\n",
        "                continue\n",
        "            \n",
        "            problem_name = problem_dir.name\n",
        "            \n",
        "            # ì¦ê°• WAV íŒŒì¼ ìˆ˜ì§‘\n",
        "            aug_files = list(problem_dir.glob('*.wav'))\n",
        "            for f in aug_files:\n",
        "                all_files.append(f)\n",
        "                all_states.append(state_idx)\n",
        "                all_problems.append(f\"{state_name}/{problem_name}\")\n",
        "            \n",
        "            # í•˜ìœ„ í´ë”ë„ í™•ì¸\n",
        "            for sub_dir in problem_dir.iterdir():\n",
        "                if sub_dir.is_dir():\n",
        "                    sub_files = list(sub_dir.glob('*.wav'))\n",
        "                    for f in sub_files:\n",
        "                        all_files.append(f)\n",
        "                        all_states.append(state_idx)\n",
        "                        all_problems.append(f\"{state_name}/{problem_name}/{sub_dir.name}\")\n",
        "\n",
        "augmented_count = len(all_files) - original_count\n",
        "print(f\"   ì¦ê°• ìƒ˜í”Œ: {augmented_count}ê°œ\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(f\"ğŸ“Š ì´ ë°ì´í„°: {len(all_files)}ê°œ\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# ìƒíƒœë³„ ë¶„í¬ í™•ì¸\n",
        "state_counts = Counter(all_states)\n",
        "print(\"\\nğŸ“Š ìƒíƒœë³„ ë¶„í¬:\")\n",
        "for idx, name in enumerate(state_names):\n",
        "    print(f\"  [{idx}] {name}: {state_counts[idx]}ê°œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# í”¼ì²˜ ì¶”ì¶œê¸° ì´ˆê¸°í™”\n",
        "# ============================================================\n",
        "\n",
        "audio_config = AudioConfig(\n",
        "    sample_rate=22050,\n",
        "    duration=5.0,\n",
        "    n_mels=128,\n",
        "    n_mfcc=40,\n",
        "    n_fft=2048,\n",
        "    hop_length=512\n",
        ")\n",
        "\n",
        "feature_extractor = AudioFeatureExtractor(config=audio_config)\n",
        "print(\"âœ… í”¼ì²˜ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# í”¼ì²˜ ì¶”ì¶œ (êµ°ì§‘ ë¶„ì„ìš©)\n",
        "# ============================================================\n",
        "\n",
        "print(\"ğŸ”„ í”¼ì²˜ ì¶”ì¶œ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\")\n",
        "\n",
        "# ëª¨ë“  ìƒ˜í”Œì—ì„œ í”¼ì²˜ ì¶”ì¶œ\n",
        "all_features = []\n",
        "\n",
        "for file_path in tqdm(all_files, desc=\"í”¼ì²˜ ì¶”ì¶œ\"):\n",
        "    try:\n",
        "        # CNNìš© í”¼ì²˜ ì¶”ì¶œ (Mel Spectrogram)\n",
        "        features = feature_extractor.extract_for_cnn(str(file_path))\n",
        "        # Flattení•˜ì—¬ 1D ë²¡í„°ë¡œ ë³€í™˜\n",
        "        features_flat = features.flatten()\n",
        "        all_features.append(features_flat)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        # ì˜¤ë¥˜ ì‹œ 0ìœ¼ë¡œ ì±„ì›€\n",
        "        all_features.append(np.zeros(128 * 216))\n",
        "\n",
        "# NumPy ë°°ì—´ë¡œ ë³€í™˜\n",
        "X = np.array(all_features)\n",
        "y_state = np.array(all_states)\n",
        "\n",
        "print(f\"\\nâœ… í”¼ì²˜ ì¶”ì¶œ ì™„ë£Œ!\")\n",
        "print(f\"   X shape: {X.shape}\")\n",
        "print(f\"   y_state shape: {y_state.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. PCA ì‹œê°í™” ë° êµ°ì§‘ ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ë°ì´í„° ì •ê·œí™” ë° PCA\n",
        "# ============================================================\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(f\"âœ… ë°ì´í„° ì •ê·œí™” ì™„ë£Œ!\")\n",
        "\n",
        "# 2D PCA\n",
        "print(\"ğŸ”„ PCA ìˆ˜í–‰ ì¤‘...\")\n",
        "pca_2d = PCA(n_components=2, random_state=42)\n",
        "X_pca_2d = pca_2d.fit_transform(X_scaled)\n",
        "\n",
        "print(f\"\\nâœ… PCA (2D) ì™„ë£Œ!\")\n",
        "print(f\"   ì„¤ëª…ëœ ë¶„ì‚° ë¹„ìœ¨: {pca_2d.explained_variance_ratio_.sum():.4f}\")\n",
        "print(f\"   PC1: {pca_2d.explained_variance_ratio_[0]:.4f}\")\n",
        "print(f\"   PC2: {pca_2d.explained_variance_ratio_[1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# PCA 2D ì‹œê°í™” (ì‹¤ì œ ë ˆì´ë¸” ê¸°ì¤€)\n",
        "# ============================================================\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']  # ë¹¨ê°•, ì²­ë¡, íŒŒë‘\n",
        "markers = ['o', 's', '^']\n",
        "\n",
        "for idx, (name, color, marker) in enumerate(zip(state_names, colors, markers)):\n",
        "    mask = y_state == idx\n",
        "    ax.scatter(\n",
        "        X_pca_2d[mask, 0], \n",
        "        X_pca_2d[mask, 1], \n",
        "        c=color, \n",
        "        marker=marker,\n",
        "        label=f'{name} (n={mask.sum()})',\n",
        "        alpha=0.6,\n",
        "        s=50\n",
        "    )\n",
        "\n",
        "ax.set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]:.2%})', fontsize=12)\n",
        "ax.set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]:.2%})', fontsize=12)\n",
        "ax.set_title('ğŸ¯ PCA 2D ì‹œê°í™” - ì‹¤ì œ ë ˆì´ë¸”', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best', fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nğŸ’¡ í•´ì„:\")\n",
        "print(\"  â€¢ ê°™ì€ ìƒ‰ìƒ(ìƒíƒœ)ì˜ ì ë“¤ì´ ëª¨ì—¬ìˆì„ìˆ˜ë¡ ë¶„ë¥˜ê°€ ì‰¬ì›€\")\n",
        "print(\"  â€¢ ê²¹ì¹˜ëŠ” ì˜ì—­ì´ ë§ìœ¼ë©´ ë¶„ë¥˜ê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# PCA 3D ì‹œê°í™”\n",
        "# ============================================================\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# 3D PCA\n",
        "pca_3d = PCA(n_components=3, random_state=42)\n",
        "X_pca_3d = pca_3d.fit_transform(X_scaled)\n",
        "\n",
        "print(f\"âœ… PCA (3D) ì™„ë£Œ!\")\n",
        "print(f\"   ì„¤ëª…ëœ ë¶„ì‚° ë¹„ìœ¨: {pca_3d.explained_variance_ratio_.sum():.4f}\")\n",
        "\n",
        "# 3D ì‹œê°í™”\n",
        "fig = plt.figure(figsize=(14, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "for idx, (name, color, marker) in enumerate(zip(state_names, colors, markers)):\n",
        "    mask = y_state == idx\n",
        "    ax.scatter(\n",
        "        X_pca_3d[mask, 0], \n",
        "        X_pca_3d[mask, 1], \n",
        "        X_pca_3d[mask, 2],\n",
        "        c=color, \n",
        "        marker=marker,\n",
        "        label=f'{name} (n={mask.sum()})',\n",
        "        alpha=0.6,\n",
        "        s=50\n",
        "    )\n",
        "\n",
        "ax.set_xlabel(f'PC1 ({pca_3d.explained_variance_ratio_[0]:.2%})')\n",
        "ax.set_ylabel(f'PC2 ({pca_3d.explained_variance_ratio_[1]:.2%})')\n",
        "ax.set_zlabel(f'PC3 ({pca_3d.explained_variance_ratio_[2]:.2%})')\n",
        "ax.set_title('ğŸ¯ PCA 3D ì‹œê°í™” - ì‹¤ì œ ë ˆì´ë¸”', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# K-Means í´ëŸ¬ìŠ¤í„°ë§\n",
        "# ============================================================\n",
        "\n",
        "print(\"ğŸ”„ K-Means í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰ ì¤‘...\")\n",
        "\n",
        "# K=3ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ (3ê°œ ìƒíƒœì— ë§ì¶¤)\n",
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "cluster_labels = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "print(f\"\\nâœ… K-Means í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ!\")\n",
        "\n",
        "# í´ëŸ¬ìŠ¤í„°ë³„ ë¶„í¬\n",
        "cluster_counts = Counter(cluster_labels)\n",
        "print(\"\\nğŸ“Š í´ëŸ¬ìŠ¤í„°ë³„ ìƒ˜í”Œ ìˆ˜:\")\n",
        "for cluster_id in sorted(cluster_counts.keys()):\n",
        "    print(f\"  Cluster {cluster_id}: {cluster_counts[cluster_id]}ê°œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì‹œê°í™”\n",
        "# ============================================================\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "# ì¢Œì¸¡: ì‹¤ì œ ë ˆì´ë¸”\n",
        "for idx, (name, color, marker) in enumerate(zip(state_names, colors, markers)):\n",
        "    mask = y_state == idx\n",
        "    axes[0].scatter(\n",
        "        X_pca_2d[mask, 0], \n",
        "        X_pca_2d[mask, 1], \n",
        "        c=color, \n",
        "        marker=marker,\n",
        "        label=f'{name}',\n",
        "        alpha=0.6,\n",
        "        s=50\n",
        "    )\n",
        "axes[0].set_xlabel('PC1')\n",
        "axes[0].set_ylabel('PC2')\n",
        "axes[0].set_title('âœ… ì‹¤ì œ ë ˆì´ë¸” (Ground Truth)', fontsize=12, fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# ìš°ì¸¡: K-Means í´ëŸ¬ìŠ¤í„°\n",
        "cluster_colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
        "for cluster_id in range(3):\n",
        "    mask = cluster_labels == cluster_id\n",
        "    axes[1].scatter(\n",
        "        X_pca_2d[mask, 0], \n",
        "        X_pca_2d[mask, 1], \n",
        "        c=cluster_colors[cluster_id],\n",
        "        label=f'Cluster {cluster_id}',\n",
        "        alpha=0.6,\n",
        "        s=50\n",
        "    )\n",
        "\n",
        "# í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ í‘œì‹œ\n",
        "centers_pca = pca_2d.transform(kmeans.cluster_centers_)\n",
        "axes[1].scatter(\n",
        "    centers_pca[:, 0], centers_pca[:, 1],\n",
        "    c='black', marker='X', s=200, edgecolors='white', linewidths=2,\n",
        "    label='Centroids'\n",
        ")\n",
        "\n",
        "axes[1].set_xlabel('PC1')\n",
        "axes[1].set_ylabel('PC2')\n",
        "axes[1].set_title('ğŸ”µ K-Means í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼', fontsize=12, fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('ğŸ“Š ì‹¤ì œ ë ˆì´ë¸” vs K-Means í´ëŸ¬ìŠ¤í„°ë§', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# í´ëŸ¬ìŠ¤í„°ë§ ì„±ëŠ¥ í‰ê°€\n",
        "# ============================================================\n",
        "\n",
        "# 1. Silhouette Score (êµ°ì§‘ ì‘ì§‘ë„)\n",
        "silhouette = silhouette_score(X_scaled, cluster_labels)\n",
        "\n",
        "# 2. Adjusted Rand Index (ì‹¤ì œ ë ˆì´ë¸”ê³¼ì˜ ì¼ì¹˜ë„)\n",
        "ari = adjusted_rand_score(y_state, cluster_labels)\n",
        "\n",
        "# 3. Normalized Mutual Information\n",
        "nmi = normalized_mutual_info_score(y_state, cluster_labels)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ“Š í´ëŸ¬ìŠ¤í„°ë§ ì„±ëŠ¥ í‰ê°€\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n1ï¸âƒ£ Silhouette Score: {silhouette:.4f}\")\n",
        "print(\"   (-1 ~ 1, ë†’ì„ìˆ˜ë¡ êµ°ì§‘ì´ ì˜ ë¶„ë¦¬ë¨)\")\n",
        "print(f\"\\n2ï¸âƒ£ Adjusted Rand Index (ARI): {ari:.4f}\")\n",
        "print(\"   (0 ~ 1, ë†’ì„ìˆ˜ë¡ ì‹¤ì œ ë ˆì´ë¸”ê³¼ ì¼ì¹˜)\")\n",
        "print(f\"\\n3ï¸âƒ£ Normalized Mutual Information (NMI): {nmi:.4f}\")\n",
        "print(\"   (0 ~ 1, ë†’ì„ìˆ˜ë¡ ì‹¤ì œ ë ˆì´ë¸”ê³¼ ì¼ì¹˜)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# í´ëŸ¬ìŠ¤í„°-ë ˆì´ë¸” ë§¤ì¹­ ë¶„ì„\n",
        "# ============================================================\n",
        "\n",
        "# í˜¼ë™ í–‰ë ¬: í´ëŸ¬ìŠ¤í„° vs ì‹¤ì œ ë ˆì´ë¸”\n",
        "contingency = pd.crosstab(\n",
        "    pd.Series(cluster_labels, name='Cluster'),\n",
        "    pd.Series(y_state, name='State').map(lambda x: state_names[x])\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ“Š í´ëŸ¬ìŠ¤í„°-ë ˆì´ë¸” êµì°¨í‘œ:\")\n",
        "print(contingency)\n",
        "\n",
        "# íˆíŠ¸ë§µ ì‹œê°í™”\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "sns.heatmap(\n",
        "    contingency, \n",
        "    annot=True, \n",
        "    fmt='d', \n",
        "    cmap='Blues',\n",
        "    ax=ax\n",
        ")\n",
        "ax.set_title('ğŸ” í´ëŸ¬ìŠ¤í„° vs ì‹¤ì œ ë ˆì´ë¸” ë¶„í¬', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('ì‹¤ì œ ìƒíƒœ (State)', fontsize=12)\n",
        "ax.set_ylabel('K-Means í´ëŸ¬ìŠ¤í„°', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ê° í´ëŸ¬ìŠ¤í„°ì˜ ì£¼ìš” ë ˆì´ë¸” ë¶„ì„\n",
        "print(\"\\nğŸ’¡ í´ëŸ¬ìŠ¤í„°ë³„ ì£¼ìš” êµ¬ì„±:\")\n",
        "for cluster_id in range(3):\n",
        "    cluster_mask = cluster_labels == cluster_id\n",
        "    states_in_cluster = y_state[cluster_mask]\n",
        "    state_dist = Counter(states_in_cluster)\n",
        "    \n",
        "    total = sum(state_dist.values())\n",
        "    print(f\"\\n  Cluster {cluster_id}:\")\n",
        "    for state_idx, count in sorted(state_dist.items(), key=lambda x: -x[1]):\n",
        "        pct = count / total * 100\n",
        "        print(f\"    {state_names[state_idx]}: {count}ê°œ ({pct:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. 1ë‹¨ê³„ ëª¨ë¸: ìƒíƒœ(State) ë¶„ë¥˜\n",
        "\n",
        "ë¸Œë ˆì´í¬ ìƒíƒœ / ê³µíšŒì „ ìƒíƒœ / ì‹œë™ ìƒíƒœë¥¼ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
        "# ============================================================\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "class SoundDataset(Dataset):\n",
        "    \"\"\"ì°¨ëŸ‰ ì‚¬ìš´ë“œ ë°ì´í„°ì…‹\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        file_paths: list,\n",
        "        labels: list,\n",
        "        feature_extractor: AudioFeatureExtractor,\n",
        "        augmentor: Optional[AudioAugmentor] = None,\n",
        "        apply_spec_augment: bool = False,\n",
        "        is_training: bool = True\n",
        "    ):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.augmentor = augmentor\n",
        "        self.apply_spec_augment = apply_spec_augment\n",
        "        self.is_training = is_training\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.file_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        features = self.feature_extractor.extract_for_cnn(str(file_path))\n",
        "        \n",
        "        if self.is_training and self.apply_spec_augment and self.augmentor is not None:\n",
        "            features_2d = features[0]\n",
        "            features_2d = self.augmentor.spec_augment(\n",
        "                features_2d, num_freq_masks=2, num_time_masks=2,\n",
        "                freq_mask_param=15, time_mask_param=35\n",
        "            )\n",
        "            features = features_2d[np.newaxis, ...]\n",
        "        \n",
        "        features_tensor = torch.FloatTensor(features)\n",
        "        label_tensor = torch.LongTensor([label])[0]\n",
        "        \n",
        "        return features_tensor, label_tensor\n",
        "\n",
        "print(\"âœ… SoundDataset í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 1ë‹¨ê³„ ëª¨ë¸ í•™ìŠµ ë°ì´í„° ì¤€ë¹„\n",
        "# ============================================================\n",
        "\n",
        "# ë°ì´í„° ë¶„í• \n",
        "X_train_s, X_temp_s, y_train_s, y_temp_s = train_test_split(\n",
        "    all_files, all_states,\n",
        "    test_size=0.3,\n",
        "    stratify=all_states,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_val_s, X_test_s, y_val_s, y_test_s = train_test_split(\n",
        "    X_temp_s, y_temp_s,\n",
        "    test_size=0.5,\n",
        "    stratify=y_temp_s,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"ğŸ“Š 1ë‹¨ê³„ ëª¨ë¸ (State ë¶„ë¥˜) ë°ì´í„° ë¶„í• :\")\n",
        "print(f\"  â€¢ í•™ìŠµ ì…‹: {len(X_train_s)}ê°œ\")\n",
        "print(f\"  â€¢ ê²€ì¦ ì…‹: {len(X_val_s)}ê°œ\")\n",
        "print(f\"  â€¢ í…ŒìŠ¤íŠ¸ ì…‹: {len(X_test_s)}ê°œ\")\n",
        "print(f\"  â€¢ í´ë˜ìŠ¤ ìˆ˜: 3ê°œ (braking, idle, startup)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 1ë‹¨ê³„ ëª¨ë¸ í•™ìŠµ\n",
        "# ============================================================\n",
        "\n",
        "# ì¦ê°•ê¸°\n",
        "aug_config = AugmentationConfig()\n",
        "augmentor = AudioAugmentor(config=aug_config)\n",
        "\n",
        "# ë°ì´í„°ì…‹ ìƒì„±\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_dataset_s = SoundDataset(\n",
        "    file_paths=X_train_s, labels=y_train_s,\n",
        "    feature_extractor=feature_extractor,\n",
        "    augmentor=augmentor, apply_spec_augment=True, is_training=True\n",
        ")\n",
        "\n",
        "val_dataset_s = SoundDataset(\n",
        "    file_paths=X_val_s, labels=y_val_s,\n",
        "    feature_extractor=feature_extractor,\n",
        "    augmentor=None, apply_spec_augment=False, is_training=False\n",
        ")\n",
        "\n",
        "test_dataset_s = SoundDataset(\n",
        "    file_paths=X_test_s, labels=y_test_s,\n",
        "    feature_extractor=feature_extractor,\n",
        "    augmentor=None, apply_spec_augment=False, is_training=False\n",
        ")\n",
        "\n",
        "train_loader_s = DataLoader(train_dataset_s, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader_s = DataLoader(val_dataset_s, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader_s = DataLoader(test_dataset_s, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "print(f\"âœ… DataLoader ìƒì„± ì™„ë£Œ!\")\n",
        "print(f\"   í•™ìŠµ ë°°ì¹˜: {len(train_loader_s)}, ê²€ì¦ ë°°ì¹˜: {len(val_loader_s)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 1ë‹¨ê³„ CRNN ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
        "# ============================================================\n",
        "\n",
        "NUM_STATES = 3  # braking, idle, startup\n",
        "\n",
        "# ëª¨ë¸ ìƒì„±\n",
        "state_model = SoundClassifierCRNN(\n",
        "    num_classes=NUM_STATES,\n",
        "    in_channels=1,\n",
        "    cnn_channels=[32, 64, 128],\n",
        "    rnn_hidden_size=128,\n",
        "    rnn_num_layers=2,\n",
        "    dropout=0.3,\n",
        "    bidirectional=True\n",
        ")\n",
        "state_model = state_model.to(device)\n",
        "\n",
        "print(\"ğŸ—ï¸ 1ë‹¨ê³„ ëª¨ë¸ (State ë¶„ë¥˜):\")\n",
        "print(f\"   í´ë˜ìŠ¤: {state_names}\")\n",
        "total_params = sum(p.numel() for p in state_model.parameters())\n",
        "print(f\"   íŒŒë¼ë¯¸í„°: {total_params:,}\")\n",
        "\n",
        "# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜\n",
        "state_counts_list = [state_counts[i] for i in range(NUM_STATES)]\n",
        "class_weights = 1.0 / torch.FloatTensor(state_counts_list)\n",
        "class_weights = class_weights / class_weights.sum() * NUM_STATES\n",
        "\n",
        "# í•™ìŠµ ì„¤ì •\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "optimizer = create_optimizer(state_model, 'adamw', lr=1e-3, weight_decay=0.01)\n",
        "scheduler = create_scheduler(optimizer, 'cosine', epochs=20)\n",
        "\n",
        "# ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬\n",
        "checkpoint_dir = Path('../checkpoints')\n",
        "checkpoint_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Trainer\n",
        "state_trainer = Trainer(\n",
        "    model=state_model,\n",
        "    train_loader=train_loader_s,\n",
        "    val_loader=val_loader_s,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    device=str(device),\n",
        "    save_dir=str(checkpoint_dir),\n",
        "    experiment_name='state_classifier',\n",
        "    use_amp=(device.type == 'cuda')\n",
        ")\n",
        "\n",
        "# í•™ìŠµ\n",
        "print(\"\\nğŸš€ 1ë‹¨ê³„ ëª¨ë¸ í•™ìŠµ ì‹œì‘!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "state_history = state_trainer.train(\n",
        "    epochs=20,\n",
        "    early_stopping_patience=7,\n",
        "    save_best=True,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\nâœ… 1ë‹¨ê³„ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 1ë‹¨ê³„ ëª¨ë¸ í‰ê°€\n",
        "# ============================================================\n",
        "\n",
        "def evaluate_model(model, test_loader, device, class_names, model_name=\"Model\"):\n",
        "    \"\"\"ëª¨ë¸ í‰ê°€\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in tqdm(test_loader, desc=f\"Evaluating {model_name}\"):\n",
        "            batch_x = batch_x.to(device)\n",
        "            outputs = model(batch_x)\n",
        "            _, preds = outputs.max(1)\n",
        "            \n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_y.numpy())\n",
        "    \n",
        "    accuracy = 100 * sum(p == l for p, l in zip(all_preds, all_labels)) / len(all_labels)\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ğŸ“Š {model_name} í…ŒìŠ¤íŠ¸ ê²°ê³¼\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"ì •í™•ë„: {accuracy:.2f}%\")\n",
        "    \n",
        "    print(\"\\nğŸ“‹ Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=class_names, zero_division='0'))\n",
        "    \n",
        "    # í˜¼ë™ í–‰ë ¬\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(f'{model_name} - Confusion Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return accuracy, all_preds, all_labels\n",
        "\n",
        "# Best ëª¨ë¸ ë¡œë“œ\n",
        "state_best_path = checkpoint_dir / 'state_classifier_best_model.pt'\n",
        "if state_best_path.exists():\n",
        "    checkpoint = torch.load(state_best_path, map_location=device)\n",
        "    state_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"âœ… Best ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
        "\n",
        "# í‰ê°€\n",
        "state_acc, state_preds, state_labels = evaluate_model(\n",
        "    state_model, test_loader_s, device, state_names, \"State Classifier (1ë‹¨ê³„)\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. 2ë‹¨ê³„ ëª¨ë¸: ì„¸ë¶€ ë¬¸ì œ ë¶„ë¥˜\n",
        "\n",
        "ê° ìƒíƒœë³„ë¡œ ì„¸ë¶€ ë¬¸ì œë¥¼ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "- ë¸Œë ˆì´í¬: normal_brakes, worn_out_brakes\n",
        "- ê³µíšŒì „: normal_engine_idle, low_oil, power_steering, serpentine_belt, combined/*\n",
        "- ì‹œë™: normal_engine_startup, bad_ignition, dead_battery\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ìƒíƒœë³„ ë°ì´í„° ë¶„ë¦¬\n",
        "# ============================================================\n",
        "\n",
        "# ìƒíƒœë³„ ë°ì´í„° ë¶„ë¦¬\n",
        "state_data = {0: [], 1: [], 2: []}  # braking, idle, startup\n",
        "\n",
        "for file_path, state, problem in zip(all_files, all_states, all_problems):\n",
        "    state_data[state].append((file_path, problem))\n",
        "\n",
        "print(\"ğŸ“Š ìƒíƒœë³„ ë°ì´í„° ë¶„í¬:\")\n",
        "for state_idx, name in enumerate(state_names):\n",
        "    print(f\"  {name}: {len(state_data[state_idx])}ê°œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 2ë‹¨ê³„ ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜\n",
        "# ============================================================\n",
        "\n",
        "def train_sub_classifier(\n",
        "    state_name: str,\n",
        "    state_idx: int,\n",
        "    data: list,\n",
        "    feature_extractor: AudioFeatureExtractor,\n",
        "    device: torch.device,\n",
        "    checkpoint_dir: Path,\n",
        "    epochs: int = 20\n",
        "):\n",
        "    \"\"\"íŠ¹ì • ìƒíƒœì˜ ì„¸ë¶€ ë¬¸ì œ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ğŸ”§ {state_name.upper()} ìƒíƒœ ì„¸ë¶€ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # íŒŒì¼ ê²½ë¡œì™€ ë ˆì´ë¸” ë¶„ë¦¬\n",
        "    files = [d[0] for d in data]\n",
        "    problems = [d[1] for d in data]\n",
        "    \n",
        "    # ë ˆì´ë¸” ì¸ì½”ë”©\n",
        "    unique_problems = sorted(set(problems))\n",
        "    problem_to_idx = {p: i for i, p in enumerate(unique_problems)}\n",
        "    idx_to_problem = {i: p for p, i in problem_to_idx.items()}\n",
        "    labels = [problem_to_idx[p] for p in problems]\n",
        "    \n",
        "    num_classes = len(unique_problems)\n",
        "    print(f\"\\nğŸ“Š í´ë˜ìŠ¤ ({num_classes}ê°œ):\")\n",
        "    label_counts = Counter(labels)\n",
        "    for idx, problem in idx_to_problem.items():\n",
        "        short_name = problem.split('/')[-1]\n",
        "        print(f\"  [{idx}] {short_name}: {label_counts[idx]}ê°œ\")\n",
        "    \n",
        "    # ë°ì´í„° ë¶„í• \n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        files, labels, test_size=0.3, stratify=labels, random_state=42\n",
        "    )\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nğŸ“Š ë°ì´í„° ë¶„í• : Train {len(X_train)}, Val {len(X_val)}, Test {len(X_test)}\")\n",
        "    \n",
        "    # ë°ì´í„°ì…‹ ìƒì„±\n",
        "    aug_config = AugmentationConfig()\n",
        "    augmentor = AudioAugmentor(config=aug_config)\n",
        "    \n",
        "    train_dataset = SoundDataset(\n",
        "        file_paths=X_train, labels=y_train,\n",
        "        feature_extractor=feature_extractor,\n",
        "        augmentor=augmentor, apply_spec_augment=True, is_training=True\n",
        "    )\n",
        "    val_dataset = SoundDataset(\n",
        "        file_paths=X_val, labels=y_val,\n",
        "        feature_extractor=feature_extractor,\n",
        "        augmentor=None, apply_spec_augment=False, is_training=False\n",
        "    )\n",
        "    test_dataset = SoundDataset(\n",
        "        file_paths=X_test, labels=y_test,\n",
        "        feature_extractor=feature_extractor,\n",
        "        augmentor=None, apply_spec_augment=False, is_training=False\n",
        "    )\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
        "    \n",
        "    # ëª¨ë¸ ìƒì„±\n",
        "    model = SoundClassifierCRNN(\n",
        "        num_classes=num_classes,\n",
        "        in_channels=1,\n",
        "        cnn_channels=[32, 64, 128],\n",
        "        rnn_hidden_size=128,\n",
        "        rnn_num_layers=2,\n",
        "        dropout=0.3,\n",
        "        bidirectional=True\n",
        "    )\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜\n",
        "    class_counts_list = [label_counts.get(i, 1) for i in range(num_classes)]\n",
        "    class_weights = 1.0 / torch.FloatTensor(class_counts_list)\n",
        "    class_weights = class_weights / class_weights.sum() * num_classes\n",
        "    \n",
        "    # í•™ìŠµ ì„¤ì •\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "    optimizer = create_optimizer(model, 'adamw', lr=1e-3, weight_decay=0.01)\n",
        "    scheduler = create_scheduler(optimizer, 'cosine', epochs=epochs)\n",
        "    \n",
        "    # Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        device=str(device),\n",
        "        save_dir=str(checkpoint_dir),\n",
        "        experiment_name=f'{state_name}_sub_classifier',\n",
        "        use_amp=(device.type == 'cuda')\n",
        "    )\n",
        "    \n",
        "    # í•™ìŠµ\n",
        "    print(f\"\\nğŸš€ í•™ìŠµ ì‹œì‘!\")\n",
        "    history = trainer.train(\n",
        "        epochs=epochs,\n",
        "        early_stopping_patience=7,\n",
        "        save_best=True,\n",
        "        verbose=True\n",
        "    )\n",
        "    \n",
        "    # Best ëª¨ë¸ ë¡œë“œ\n",
        "    best_path = checkpoint_dir / f'{state_name}_sub_classifier_best_model.pt'\n",
        "    if best_path.exists():\n",
        "        checkpoint = torch.load(best_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    \n",
        "    # í‰ê°€\n",
        "    class_names = [idx_to_problem[i].split('/')[-1] for i in range(num_classes)]\n",
        "    accuracy, preds, labels_result = evaluate_model(\n",
        "        model, test_loader, device, class_names, f\"{state_name.upper()} Sub-Classifier\"\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'model': model,\n",
        "        'history': history,\n",
        "        'accuracy': accuracy,\n",
        "        'problem_to_idx': problem_to_idx,\n",
        "        'idx_to_problem': idx_to_problem,\n",
        "        'class_names': class_names\n",
        "    }\n",
        "\n",
        "print(\"âœ… í•™ìŠµ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 2ë‹¨ê³„ ëª¨ë¸ 1: ë¸Œë ˆì´í¬ ìƒíƒœ ì„¸ë¶€ ë¶„ë¥˜\n",
        "# ============================================================\n",
        "\n",
        "braking_result = train_sub_classifier(\n",
        "    state_name='braking',\n",
        "    state_idx=0,\n",
        "    data=state_data[0],\n",
        "    feature_extractor=feature_extractor,\n",
        "    device=device,\n",
        "    checkpoint_dir=checkpoint_dir,\n",
        "    epochs=20\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 2ë‹¨ê³„ ëª¨ë¸ 2: ê³µíšŒì „ ìƒíƒœ ì„¸ë¶€ ë¶„ë¥˜\n",
        "# ============================================================\n",
        "\n",
        "idle_result = train_sub_classifier(\n",
        "    state_name='idle',\n",
        "    state_idx=1,\n",
        "    data=state_data[1],\n",
        "    feature_extractor=feature_extractor,\n",
        "    device=device,\n",
        "    checkpoint_dir=checkpoint_dir,\n",
        "    epochs=20\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 2ë‹¨ê³„ ëª¨ë¸ 3: ì‹œë™ ìƒíƒœ ì„¸ë¶€ ë¶„ë¥˜\n",
        "# ============================================================\n",
        "\n",
        "startup_result = train_sub_classifier(\n",
        "    state_name='startup',\n",
        "    state_idx=2,\n",
        "    data=state_data[2],\n",
        "    feature_extractor=feature_extractor,\n",
        "    device=device,\n",
        "    checkpoint_dir=checkpoint_dir,\n",
        "    epochs=20\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. ìµœì¢… ê²°ê³¼ ìš”ì•½\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ì „ì²´ ê²°ê³¼ ìš”ì•½\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"ğŸ‰ ê³„ì¸µì  ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\"\"\n",
        "ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½:\n",
        "\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ 1ë‹¨ê³„: State ë¶„ë¥˜ ëª¨ë¸                                           â”‚\n",
        "â”‚   â€¢ í´ë˜ìŠ¤: braking, idle, startup (3ê°œ)                         â”‚\n",
        "â”‚   â€¢ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {state_acc:.2f}%                                â”‚\n",
        "â”‚   â€¢ ì €ì¥ ê²½ë¡œ: checkpoints/state_classifier_best_model.pt        â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ 2ë‹¨ê³„: ì„¸ë¶€ ë¶„ë¥˜ ëª¨ë¸                                            â”‚\n",
        "â”‚                                                                 â”‚\n",
        "â”‚   [Braking] ë¸Œë ˆì´í¬ ìƒíƒœ ì„¸ë¶€ ë¶„ë¥˜                              â”‚\n",
        "â”‚     â€¢ í´ë˜ìŠ¤: {braking_result['class_names']}\n",
        "â”‚     â€¢ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {braking_result['accuracy']:.2f}%\n",
        "â”‚                                                                 â”‚\n",
        "â”‚   [Idle] ê³µíšŒì „ ìƒíƒœ ì„¸ë¶€ ë¶„ë¥˜                                   â”‚\n",
        "â”‚     â€¢ í´ë˜ìŠ¤: {len(idle_result['class_names'])}ê°œ\n",
        "â”‚     â€¢ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {idle_result['accuracy']:.2f}%\n",
        "â”‚                                                                 â”‚\n",
        "â”‚   [Startup] ì‹œë™ ìƒíƒœ ì„¸ë¶€ ë¶„ë¥˜                                  â”‚\n",
        "â”‚     â€¢ í´ë˜ìŠ¤: {startup_result['class_names']}\n",
        "â”‚     â€¢ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {startup_result['accuracy']:.2f}%\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "ğŸ” êµ°ì§‘ ë¶„ì„ ê²°ê³¼:\n",
        "  â€¢ Silhouette Score: {silhouette:.4f}\n",
        "  â€¢ Adjusted Rand Index: {ari:.4f}\n",
        "  â€¢ Normalized Mutual Info: {nmi:.4f}\n",
        "\n",
        "ğŸ“ ì €ì¥ëœ ëª¨ë¸:\n",
        "  â€¢ checkpoints/state_classifier_best_model.pt\n",
        "  â€¢ checkpoints/braking_sub_classifier_best_model.pt\n",
        "  â€¢ checkpoints/idle_sub_classifier_best_model.pt\n",
        "  â€¢ checkpoints/startup_sub_classifier_best_model.pt\n",
        "\"\"\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ê³„ì¸µì  ì¶”ë¡  ì˜ˆì‹œ\n",
        "# ============================================================\n",
        "\n",
        "def hierarchical_predict(audio_path, state_model, sub_models, feature_extractor, device):\n",
        "    \"\"\"\n",
        "    ê³„ì¸µì  ë¶„ë¥˜ ìˆ˜í–‰\n",
        "    1ë‹¨ê³„: ìƒíƒœ(State) ì˜ˆì¸¡\n",
        "    2ë‹¨ê³„: í•´ë‹¹ ìƒíƒœì˜ ì„¸ë¶€ ë¬¸ì œ ì˜ˆì¸¡\n",
        "    \"\"\"\n",
        "    # í”¼ì²˜ ì¶”ì¶œ\n",
        "    features = feature_extractor.extract_for_cnn(str(audio_path))\n",
        "    input_tensor = torch.FloatTensor(features).unsqueeze(0).to(device)\n",
        "    \n",
        "    # 1ë‹¨ê³„: ìƒíƒœ ì˜ˆì¸¡\n",
        "    state_model.eval()\n",
        "    with torch.no_grad():\n",
        "        state_output = state_model(input_tensor)\n",
        "        state_probs = torch.softmax(state_output, dim=1)\n",
        "        state_pred = state_output.argmax(dim=1).item()\n",
        "        state_conf = state_probs[0, state_pred].item() * 100\n",
        "    \n",
        "    state_name = state_names[state_pred]\n",
        "    \n",
        "    # 2ë‹¨ê³„: ì„¸ë¶€ ë¬¸ì œ ì˜ˆì¸¡\n",
        "    sub_model_info = sub_models[state_pred]\n",
        "    sub_model = sub_model_info['model']\n",
        "    idx_to_problem = sub_model_info['idx_to_problem']\n",
        "    \n",
        "    sub_model.eval()\n",
        "    with torch.no_grad():\n",
        "        sub_output = sub_model(input_tensor)\n",
        "        sub_probs = torch.softmax(sub_output, dim=1)\n",
        "        sub_pred = sub_output.argmax(dim=1).item()\n",
        "        sub_conf = sub_probs[0, sub_pred].item() * 100\n",
        "    \n",
        "    problem_name = idx_to_problem[sub_pred].split('/')[-1]\n",
        "    \n",
        "    return {\n",
        "        'state': state_name,\n",
        "        'state_confidence': state_conf,\n",
        "        'problem': problem_name,\n",
        "        'problem_confidence': sub_conf\n",
        "    }\n",
        "\n",
        "# ì„œë¸Œ ëª¨ë¸ ë”•ì…”ë„ˆë¦¬\n",
        "sub_models = {\n",
        "    0: braking_result,\n",
        "    1: idle_result,\n",
        "    2: startup_result\n",
        "}\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ìƒ˜í”Œë¡œ ì˜ˆì¸¡ ì‹œì—°\n",
        "import random\n",
        "test_samples = random.sample(list(zip(X_test_s, y_test_s)), min(5, len(X_test_s)))\n",
        "\n",
        "print(\"ğŸ§ª ê³„ì¸µì  ì¶”ë¡  ì˜ˆì‹œ:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for sample_path, true_state in test_samples:\n",
        "    result = hierarchical_predict(\n",
        "        sample_path, state_model, sub_models, feature_extractor, device\n",
        "    )\n",
        "    \n",
        "    true_state_name = state_names[true_state]\n",
        "    is_correct = \"âœ…\" if result['state'] == true_state_name else \"âŒ\"\n",
        "    \n",
        "    print(f\"\\níŒŒì¼: {sample_path.name}\")\n",
        "    print(f\"  ì‹¤ì œ ìƒíƒœ: {true_state_name}\")\n",
        "    print(f\"  ì˜ˆì¸¡ ê²°ê³¼: {is_correct}\")\n",
        "    print(f\"    1ë‹¨ê³„: {result['state']} ({result['state_confidence']:.1f}%)\")\n",
        "    print(f\"    2ë‹¨ê³„: {result['problem']} ({result['problem_confidence']:.1f}%)\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
